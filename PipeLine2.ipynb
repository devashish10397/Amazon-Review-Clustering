{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_3-G-liCDmlPJqOUv3vfpYPeSSA5__oF",
      "authorship_tag": "ABX9TyMWsyhhsAWKN1cii/7quy43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devashish10397/Amazon-Review-Clustering/blob/main/PipeLine2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "VyJs2_9yULFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOOXKb9sRMn5"
      },
      "outputs": [],
      "source": [
        "\n",
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "import os\n",
        "from PIL import Image, ImageFilter\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gW9rgehhUN0y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Tweet (playing with data frame)"
      ],
      "metadata": {
        "id": "H8hP-vhPXfcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the csv (tweetid, url, text)"
      ],
      "metadata": {
        "id": "BCrpKhvCXQYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = '/content/drive/MyDrive/Bend_pipeline/media_links_text_url.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "lLvVysNbUT4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0cb5237-f0b7-4a6b-d4f3-e37458afa780"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Tweet ID', 'Media Links', 'full_text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the tweetid you want to retrieve text for\n"
      ],
      "metadata": {
        "id": "fESx916qXYXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tweetid_to_text(desired_tweetid, df):\n",
        "    # Find the row where tweetid matches the desired_tweetid and extract the text\n",
        "    try:\n",
        "            # Find the row where tweetid matches the desired_tweetid and extract the text\n",
        "            print(\"desired_tweetid:\", desired_tweetid)\n",
        "            matching_row = df[df['tweetid'] == desired_tweetid]\n",
        "            text = ''\n",
        "            if not matching_row.empty:\n",
        "                text = matching_row.iloc[0]['text']\n",
        "                print(f\"Text for tweetid {desired_tweetid}: {text}\")\n",
        "            else:\n",
        "                print(f\"No matching tweetid {desired_tweetid} found in the CSV.\")\n",
        "            return text\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}. 'tweetid' column not found in the DataFrame.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "yZUSXotLXWLS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make CSV with pixel data, tweet and ocr info\n"
      ],
      "metadata": {
        "id": "HiH3qYk0YDp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input and output folders\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lqsjT5gjUTIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_folder = \"/content/drive/MyDrive/Bend_pipeline/final_test_images\"\n",
        "output_folder = \"/content/drive/MyDrive/Bend_pipeline\""
      ],
      "metadata": {
        "id": "DWLIcUDKUSMw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do OCR and image to pixel conversion"
      ],
      "metadata": {
        "id": "bGW60-HfU7x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_size = (800, 800)\n",
        "\n",
        "image_text_data = []\n",
        "\n",
        "image_files = os.listdir(input_folder)\n",
        "\n",
        "#Only for first 100 images\n",
        "for image_file in image_files[:10]:\n",
        "    image_path = os.path.join(input_folder, image_file)\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    if img.mode == 'P':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    img = img.resize(target_size, Image.LANCZOS)\n",
        "    img = img.filter(ImageFilter.SHARPEN)\n",
        "\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    # print(text)\n",
        "    # image_text_data.append([image_file, text])\n",
        "    # Get the pixel data as a list\n",
        "    pixel_data = list(img.getdata())\n",
        "    # Perform OCR and get extracted text\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    tweet_id = image_file[:-4]\n",
        "    full_text = tweetid_to_text(tweet_id, df)\n",
        "    print(\"full text\", full_text)\n",
        "    print(f\"Extracted text from {image_file}: {text}\")\n",
        "    image_text_data.append([tweet_id, pixel_data, text, full_text])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8awPVcMnVAa9",
        "outputId": "51134838-01e6-4142-bc10-2bba07c21e44"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "desired_tweetid: 1576310618776563712\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576310618776563712.jpg:  \n",
            "\f\n",
            "desired_tweetid: 1576313682123841537\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576313682123841537.jpg:  \n",
            "\f\n",
            "desired_tweetid: 1576313518248579072\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576313518248579072.jpg:  \n",
            "\f\n",
            "desired_tweetid: 1576311316587106304\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576311316587106304.jpg: ‘ GET *\n",
            "‘ VACCINATED jim\n",
            "\n",
            " \n",
            "\f\n",
            "desired_tweetid: 1576312181691363328\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576312181691363328.jpg:  \n",
            "\n",
            " \n",
            "\f\n",
            "desired_tweetid: 1576310431836094465\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576310431836094465.jpg:  \n",
            "\f\n",
            "desired_tweetid: 1576326704070819840\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576326704070819840.jpg: \f\n",
            "desired_tweetid: 1576288508146159616\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576288508146159616.jpg:  \n",
            "\f\n",
            "desired_tweetid: 1576321859456446464\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576321859456446464.jpg:  \n",
            "\f\n",
            "desired_tweetid: 1576319719501877248\n",
            "Error: 'tweetid'. 'tweetid' column not found in the DataFrame.\n",
            "full text None\n",
            "Extracted text from 1576319719501877248.jpg:  \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of image_text_data\n",
        "print(f\"Length of image_text_data: {len(image_text_data)}\")\n",
        "# Print the first 10 values of image_text_data\n",
        "print(\"First 10 values of image_text_data:\")\n",
        "for i, item in enumerate(image_text_data[:10]):\n",
        "    print(f\"Item {i + 1}: {item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXOy8KJyaT5U",
        "outputId": "eff343d1-bb7c-4bea-d7b5-5bd5cb84cd3c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save in csv"
      ],
      "metadata": {
        "id": "0PwLwJMMWuW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Define the CSV file path within the output folder\n",
        "csv_file = os.path.join(output_folder, '/content/drive/MyDrive/Bend_pipeline/final_pipeline_output_10.csv')\n",
        "\n",
        "# Create the CSV file with header\n",
        "with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['Image File', 'pixel_data', 'OCR Text', \"Full Text\"])"
      ],
      "metadata": {
        "id": "5DYeyx6ca41e"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['Image File', 'pixel_data', 'OCR Text', \"Full Text\"])\n",
        "    csv_writer.writerows(image_text_data)"
      ],
      "metadata": {
        "id": "aHLvQBTCWv9H"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}